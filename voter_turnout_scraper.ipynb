{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voter_turnout_scraper.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amanda-price/AstroHackWeek2016/blob/master/voter_turnout_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "R4AuDUhYKX0J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Decoding Democracy workshop - PDF Scraper\n",
        "<br>\n",
        "\n",
        "We will be using this Jupyter notebook to execute the pdf scraping. It works by execute code one cell at a time. Inside each shaded grey box, there will be code. To run the code:\n",
        "1. Hover over the brackets on the left of the cell [    ]  and a \"play\" button will appear. Clicking this button will run the code inside that cell. \n",
        "*Additionally, you can press Shift + Enter to run the cell*\n",
        "<br>\n",
        "2. While the code runs, the button will look like a square. If you need to quit running the code, press the button to stop execution.\n",
        "<br>\n",
        "3. Once the code is done, there will be a number inside the brackets [ 1 ]. This indicates the order in which the cells have been run. \n",
        "<br>\n",
        "4. If the code creates any output, it will be displayed below the cell. For part of this code, it might be useful to interact with this output in full screen. To do so, select the menu with three dots on the right side of the code block and select \"View output fullscreen\".\n"
      ]
    },
    {
      "metadata": {
        "id": "AiesaJg35sjE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Section 1:\n",
        "## Make a new directory and download the file"
      ]
    },
    {
      "metadata": {
        "id": "pvPX8JsiKQdb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This is a comment, it will not be run as part of the code's execution. Read these to understand what the code below it is doing!\n",
        "\n",
        "#Run this code and make sure the output says \"Hello World!\"\n",
        "print(\"Hello World!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmhi8b2-Kifw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next cell will make the directory, change to it and then display the information. Being able to invoke shell commands alongside Python code (or other languages). These commands are preceded by ! or %\n",
        "\n",
        "### IMPORTANT: Change this directory name to the year you are working on!"
      ]
    },
    {
      "metadata": {
        "id": "VbLKA4DuKpP5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make a new directory (mkdir)\n",
        "\n",
        "## CHANGE THIS TO THE YEAR YOU ARE WORKING ON\n",
        "!mkdir 2012\n",
        "\n",
        "# Change to that directory (cd)\n",
        "\n",
        "## CHANGE THIS AS WELL\n",
        "%cd '2012'\n",
        "\n",
        "# Make sure we have changed path by printing the working directory (pwd)\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HtHlbi4Kpn8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The file path should look like * /content/YYYY*\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "\n",
        "Next, we will download the file. \n",
        "\n",
        "###IMPORTANT: Change the URL to reflect the file you are working on \n",
        "To do so: \n",
        "\n",
        "1.   Go to the [Github page](https://github.com/amanda-price/decoding-democracy) and navigate to the file you are working on. \n",
        "2.   Click on the file name.\n",
        "3.   In the upper right hand corner, _right click_ the Download button and select \"Copy Link Address\". \n",
        "4.   Paste this address below after _wget_\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zqmfuNDeK9mf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Change the url to the pdf you are interested in\n",
        "## CHANGE THIS\n",
        "!wget https://github.com/amanda-price/decoding-democracy/raw/master/2012/20121106_general_precinct.pdf\n",
        "\n",
        "\n",
        "#We will then display the list of files to make sure it downloaded\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_PjBQSeOA31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br>The file name should appear as the last line from the code above. If not, check the URL path and try again!"
      ]
    },
    {
      "metadata": {
        "id": "XKZroj1h5u-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Section 2\n",
        "## Load all the necessary packages and functions"
      ]
    },
    {
      "metadata": {
        "id": "GsFft_mILxbh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run each cell in this block of codes before trying the main code below. This will install the packages and compile the functions needed. <br><br>\n",
        "After each code block is run, you do not need to rerun them unless you make a change to them. "
      ]
    },
    {
      "metadata": {
        "id": "kElP4I1l6F74",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install and load PDF scraper package\n",
        "!pip install PyMuPDF\n",
        "\n",
        "import fitz\n",
        "from copy import deepcopy\n",
        "import time\n",
        "from math import ceil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2W3CsscIOqH0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The message \"Successfully installed PyMuPDF-1.14.12\" should have been produced above. If not, there is an error installing the PDF scraping package.\n",
        "<br><br>\n",
        "The rest of the functions below will not produce an output. Make sure there is a number (i.e. [ 4 ] ) that appears after you run the code block. "
      ]
    },
    {
      "metadata": {
        "id": "X9o3eDno0Zo1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define some functions to use later\n",
        "def fetch_and_clean_text_from_page(document,page_index):\n",
        "\t# Returns a list where each item is a segment of text between \n",
        "\t# two carriage returns and some basic data-entry mistakes have been corrected\n",
        "\n",
        "\t# load a page\n",
        "\tpage = document.loadPage(page_index)\n",
        "\t# get the text on the page\n",
        "\ttext = page.getText(\"text\")\n",
        "  \n",
        "\t# replace possible stupid errors that occur throughout the document\n",
        "\ttext=text.replace('Times\\nCounted','Times Counted')\n",
        "\ttext=text.replace('times\\ncounted','Times Counted')\n",
        "\ttext=text.replace('TIMES\\nCOUNTED','Times Counted')\n",
        "\ttext=text.replace('Times \\nCounted','Times Counted')\n",
        "\ttext=text.replace('times \\ncounted','Times Counted')\n",
        "\ttext=text.replace('TIMES \\nCOUNTED','Times Counted')\n",
        "\n",
        "\t# remove the header which can be identified because the last line of the \n",
        "\t# header is \"Page: x of y\" where y is the total number of pages in the \n",
        "\t# document so the text \"of y\" is the same on every page\n",
        "\ttext=text.split('of '+str(document.pageCount)+'\\n')\n",
        "  \n",
        "\t# split the text into data entries according to carriage returns\n",
        "\ttext=text[1].split('\\n')\n",
        "\n",
        "\t# remove \"CITYWIDE\" if it occurs\n",
        "\tif text[0].startswith('CITYWIDE'):\n",
        "\t\ttext=text[1:]\n",
        "    \n",
        "\t# sometimes the last entry is empty because the text on the page ends with a carriage return\n",
        "\tif len(text[-1])==0:\n",
        "\t\ttext=text[:-1]\n",
        "\n",
        "\treturn text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qyyB6xOz0c7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_column_labels_from_text(text_list):\n",
        "  \n",
        "\t\n",
        "\tcolumn_start_ndx=list(map(lambda x: len(x)>0 and (not x.startswith('    '))  and (not x[0].isdigit()) and (not '-'==x) , text)).index(True)\n",
        "\tcolumn_stop_ndx=list(map(lambda x: len(x)>0 and (not x.startswith('    '))  and (x[0].isdigit() or '-'==x) , text)).index(True)\n",
        "\tcolumn_labels=text[column_start_ndx:(column_stop_ndx-1)]\n",
        "\t\n",
        "  # control for line breaks in column headers\n",
        "\tif any(list(map(lambda x: len(x)>0 and (x.endswith(' ')) , text))):\n",
        "\t\tcolumn_labels2=[]\n",
        "\t\tskip_next=False\n",
        "\t\tfor clmndx in range(len(column_labels)):\n",
        "\t\t\tif skip_next:\n",
        "\t\t\t\tskip_next=False\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif column_labels[clmndx].endswith(' ') and column_labels[clmndx].count(' ')<=2:\n",
        "\t\t\t\tskip_next=True\n",
        "\t\t\t\tcolumn_labels2.append(column_labels[clmndx]+column_labels[clmndx+1])\n",
        "\t\t\telse:\n",
        "\t\t\t\tskip_next=False\n",
        "\t\t\t\tcolumn_labels2.append(column_labels[clmndx])\n",
        "\t\tcolumn_labels=deepcopy(column_labels2);\n",
        "\t\tcolumn_labels2=[]\n",
        "\t\n",
        "  # control for improperly split column headers\n",
        "\tif any(list(map(lambda x: len(x)>0 and (x.count(' ')>1 and x.count(' ')%2==1) , text))):\n",
        "\t\tcolumn_labels2=[]\n",
        "\t\tfor clmndx in range(len(column_labels)):\n",
        "\t\t\tif (column_labels[clmndx].count(' ')>1 and column_labels[clmndx].count(' ')%2==1):\n",
        "\t\t\t\tsplit_label=column_labels[clmndx].split(' ')\n",
        "\t\t\t\tfor splitndx in range(0,len(split_label),2):\n",
        "\t\t\t\t\tcolumn_labels2.append(split_label[splitndx]+' '+split_label[splitndx+1])\n",
        "\t\t\telse:\n",
        "\t\t\t\tcolumn_labels2.append(column_labels[clmndx])\n",
        "\t\tcolumn_labels=deepcopy(column_labels2);\n",
        "\t\tcolumn_labels2=[]\n",
        "\n",
        "\treturn column_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuxwgcjF0fE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def identify_page_type(text_list,column_labels):\n",
        "  \n",
        "\tcolumn_stop_ndx=list(map(lambda x: len(x)>0 and (not x.startswith('    '))  and (x[0].isdigit() or '-'==x) , text)).index(True)\n",
        "\tques_count=sum(list(map(lambda x: len(x)>0 and (x.startswith('Reg.')) , column_labels)))\n",
        "\tif ques_count==0:\n",
        "\t\tif 'TURN OUT'==text_list[column_stop_ndx-1].upper() or 'TURNOUT'==text_list[column_stop_ndx-1].upper() or 'TURN OUT'==text_list[column_stop_ndx].upper() or 'TURNOUT'==text_list[column_stop_ndx].upper():\n",
        "\t\t\tpage_type='turnout'\n",
        "\t\t\tentries_in_column=[1 for i in range(len(column_labels))]\n",
        "\t\telse:\n",
        "\t\t\tpage_type='overflow'\n",
        "\t\t\tentries_in_column=[2 for i in range(len(column_labels))]\n",
        "\telse:\n",
        "\t\tpage_type='question'\n",
        "\n",
        "\treturn page_type"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_i8iJJSh0hNf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def correct_columns_and_identify_number_of_entries_in_each_data_column(column_labels,page_type):\n",
        "    \n",
        "\tques_count=sum(list(map(lambda x: len(x)>0 and (x.startswith('Reg.')) , column_labels)))\n",
        "\tcolumn_labels = checkColumnLabels(column_labels)\n",
        "\n",
        "\tif page_type=='turnout':        \n",
        "\t\tentries_in_column=[1 for i in range(len(column_labels))] \n",
        "\telif page_type=='overflow':\n",
        "\t\tentries_in_column=[2 for i in range(len(column_labels))]\n",
        "\telse:\n",
        "\t\tques_start_ndcs=[i for i in range(len(column_labels)) if (len(column_labels[i])>0 and column_labels[i].startswith('Reg.'))]\n",
        "\n",
        "\t\tif ques_count==1 and ques_start_ndcs[0]==0:\n",
        "\t\t\tentries_in_column=[1 for i in range(3)]+[2 for i in range(len(column_labels)-3)]\n",
        "\t\telse:\n",
        "\t\t\tques_start_ndcs2=[x for x in ques_start_ndcs if x!=0]\n",
        "\t\t\tcolumn_labels2=[]\n",
        "\t\t\tentries_in_column=[]\n",
        "\t\t\tfor clmndx in range(len(column_labels)):\n",
        "\t\t\t\tif column_labels[clmndx].startswith(\"Reg.\") or column_labels[clmndx].startswith(\"Times Counted\") or column_labels[clmndx].startswith(\"Total Votes\"):\n",
        "\t\t\t\t\tentries_in_column.append(1)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tentries_in_column.append(2)\n",
        "\n",
        "\treturn column_labels,entries_in_column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fI2XNuwu0i9e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def checkColumnLabels(column_labels):\n",
        "  \n",
        "\tglobal raw_column_labels\n",
        "\tglobal corrected_labels\n",
        "\n",
        "\tif raw_column_labels != column_labels:\n",
        "\t\traw_column_labels = column_labels\n",
        "\t\tprint(\"These are the column labels: {}\".format(column_labels))\n",
        "\t\tprint(\"Does this list match the column labels on page {}? Y or N\".format(pageCount))\n",
        "\t\tresponse = input()\n",
        "\t\tif response.upper() == \"Y\":\n",
        "\t\t\tcorrected_labels = column_labels\n",
        "\t\telse:\n",
        "\t\t\tcorrected_labels = []\n",
        "\t\t\tfor item in column_labels:\n",
        "\t\t\t\tprint(\"Is this label correct Y or N: {}\".format(item))\n",
        "\t\t\t\tanswer = input()\n",
        "\t\t\t\tif answer.upper() ==\"Y\":\n",
        "\t\t\t\t\tcorrected_labels.append(item)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tprint(\"Input the correct label. If this label should be deleted, enter DEL: \")\n",
        "\t\t\t\t\tnew_label = input()\n",
        "\t\t\t\t\tif new_label.upper() == \"DEL\":\n",
        "\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tcorrected_labels.append(new_label.upper())\n",
        "            \n",
        "\treturn corrected_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OO57P9kW0lER",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_row_labels(text_list):\n",
        "  \n",
        "  column_start_ndx=list(map(lambda x: len(x)>0 and (not x.startswith('    '))  and (not x[0].isdigit()) and (not '-'==x) , text)).index(True)\n",
        "  row_labels=[x.replace('    ','') for x in text_list[0:column_start_ndx]]\n",
        "  if 'TOTAL' in row_labels[-1].upper() and 'TOTAL' in row_labels[-2].upper():\n",
        "    row_labels=row_labels[:-1]\n",
        "    \n",
        "  return row_labels\n",
        "    \n",
        "def extract_data_strings(text_list):\n",
        "  \n",
        "\tcolumn_stop_ndx=list(map(lambda x: len(x)>0 and (not x.startswith('    '))  and (x[0].isdigit() or '-'==x) , text)).index(True)\n",
        "\tdata_strings=text_list[column_stop_ndx:]\n",
        "\n",
        "\treturn data_strings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkW-eUY40nMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_for_errors_reading_page(data_strings,expected_size,entries_per_row):\n",
        "  \n",
        "\tif len(data_strings)<expected_size:\n",
        "\t\tdata_strings2=[]\n",
        "\t\tfor dndx in range(len(data_strings)):\n",
        "\t\t\tdata_strings2=data_strings2+deepcopy(data_strings[dndx].replace('  ',' ').split(' '))\n",
        "\t\tdata_strings=deepcopy(data_strings2)\n",
        "\t\tdata_strings2=[]\n",
        "\tsuccess=True\n",
        "\tif len(data_strings)<expected_size:\n",
        "\t\tsuccess=False\n",
        "\tif len(data_strings)>expected_size:\n",
        "\t\ttemp=[];\n",
        "\t\tfor tempndx in range(ceil(len(data_strings)/float(entries_per_row))):\n",
        "\t\t\ttemp.append([data_strings.pop(0) for x in range(min([entries_per_row,len(data_strings)]))])\n",
        "\t\tprint('size error in check_for_errors_reading_page')\n",
        "\t\tprint(temp)\n",
        "\t\tsuccess=False\n",
        "    \n",
        "\treturn success,data_strings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXrNxWdK55sS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Section 3\n",
        "## Run the main program"
      ]
    },
    {
      "metadata": {
        "id": "z9BKhmcEMDSp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This next section will execute the main part of the code. <br><br>\n",
        "Make sure you change the *file* variable to save the files correctly. They will mimic the naming convention fo the pdf you downloaded that has the date (YYYYMMDD format), general or primary, whether it is a municipal election and results granularity (precinct level). Such as *20190305_primary_municipal_precinct*\n",
        "<br><br>\n",
        "When you run the main code, you will need to check that the column labels it has extracted match the pdf. \n",
        "\n",
        "For example, the code may say:\n",
        "\n",
        "\n",
        "\n",
        "> *These are the column labels: ['Write-In Votes', 'US REP', 'DIST 1', 'Reg. Voters', 'Times Counted', 'Total Votes', 'JAMILAH NASHEED', 'Write-In Votes']<br>\n",
        "Does this candidate list match page 385? Y or N*\n",
        "\n",
        "\n",
        "\n",
        "But the entries 'US REP' and 'DIST 1' is the office, not a column label. After entering 'N', you will have the option to remove these entries. \n",
        "\n",
        "If the number of column labels does not match the expected data size, there will be an error."
      ]
    },
    {
      "metadata": {
        "id": "p4YCs0OqBshN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# enter the name for the input file without \"_precinct.pdf\"\n",
        "## CHANGE THIS\n",
        "file = \"20121106_general\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BNxmRo10YsW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# open the document, check it and allocate the object to save in\n",
        "global pageCount \n",
        "global raw_column_labels\n",
        "\n",
        "doc = fitz.open(file+\"_precinct.pdf\")\n",
        "data_frames_to_save=[];\n",
        "current_data_frame={'Name':None,'columns':None,'index':[],'collection_label':None}\n",
        "raw_column_labels = None\n",
        "\n",
        "print(\"The document is {} pages long.\".format(doc.pageCount))\n",
        "\n",
        "\n",
        "for pndx in range(doc.pageCount):\n",
        "  \n",
        "\tpageCount = int(pndx)+1\n",
        "\t# get the text from the page\n",
        "\ttext=fetch_and_clean_text_from_page(doc,pndx)\n",
        "\n",
        "\t# tentatively identify the column labels\n",
        "\tcolumn_labels=extract_column_labels_from_text(text) \n",
        "\n",
        "\tfor attempt in range(2):\n",
        "    \n",
        "\t\t# identify whether this page shows turnout results, contains the start of a \n",
        "\t\t# race/ballot-question or is an overflow for a race/ballot-question with more \n",
        "\t\t# canditates/options that can fit on one page\n",
        "\t\tpage_type=identify_page_type(text,column_labels)\n",
        "    \n",
        "\t\t# Some columns have two data entries, we need to know this, if the page\n",
        "\t\t# introduces a new race/ballot-question but this does not occur on the first\n",
        "\t\t# collumn then we need to correct our column headers\n",
        "\t\tcolumn_labels,entries_in_column=correct_columns_and_identify_number_of_entries_in_each_data_column(column_labels,page_type)\n",
        "\n",
        "\t\t# extract the labels for the rows\n",
        "\t\trow_labels=extract_row_labels(text)\n",
        "    \n",
        "\t\t# extract the actual data\n",
        "\t\tdata_strings=extract_data_strings(text)\n",
        "    \n",
        "\t\t# we need to know how may data entries per row there are so that we can \n",
        "\t\t# split the entries by number (since there is no row delimiter)\n",
        "\t\tentries_per_row=sum(entries_in_column) \n",
        "    \n",
        "\t\t# now we need to check that we extracted the data correctly by seeing if \n",
        "\t\t# the number of data strings corresponds to the number we expected\n",
        "\t\tnum_data_rows=(len(row_labels)-sum(list(map(lambda x: len(x)>0 and x.startswith('W ') , row_labels))))\n",
        "\t\texpected_size=entries_per_row*num_data_rows\n",
        "\n",
        "\t\t# now we identify the race/ballot-question\n",
        "\t\t# NOTE: if there are too many candidates/options than can fit on one page \n",
        "\t\t# the label will only occur on the las page (in otherwords this is broken)\n",
        "\t\tcolumn_stop_ndx=list(map(lambda x: len(x)>0 and (not x.startswith('    '))  and (x[0].isdigit() or '-'==x) , text)).index(True)\n",
        "\t\tcollection_label=text[column_stop_ndx-1]\n",
        "    \n",
        "\t\t# now we see if we read the data correctly, if we did then we don't need to \n",
        "\t\t# run through a second time.\n",
        "\t\tsuccess,data_strings=check_for_errors_reading_page(data_strings,expected_size,entries_per_row)\n",
        "    \n",
        "\t\tif success:\n",
        "\t\t\tbreak\n",
        "\t  \n",
        "\t# if we have run through the page parsing section twice and still have not \n",
        "\t# read things correctly then we have something to debug\n",
        "\tif not success:\n",
        "\t\terrorhere # a lazy way to make the code stop\n",
        "\n",
        "\n",
        "\t# now that we have parsed the page we need to store the data in a pandas ready dictionary\n",
        "\tempty_dict={} # this will become a blank template but it changes since each page has different collumn labels\n",
        "  \n",
        "\t# first step is to create a dictionary where each key corresponds to a data \n",
        "\t# column on the original page\n",
        "\ttemp_data_dict={}\n",
        "  \n",
        "\tfor cndx in range(len(column_labels)):\n",
        "\t\tcndx2=sum(entries_in_column[:cndx])\n",
        "\n",
        "\t\t# since there are the same number of data strings per row then every Nth \n",
        "\t\t# data_string belongs to the column (N=entries_per_row)\n",
        "\t\t# so we count off by N but need to adjust where we start counting according the column\n",
        "\t\tif entries_in_column[cndx]==1: # if this column has one entry per row\n",
        "\t\t\ttemp_data_dict[column_labels[cndx]]=[data_strings[x] for x in range(cndx2,len(data_strings),entries_per_row)] # count by N and make a list of strings\n",
        "\t\t\n",
        "\t\telse: # if this column has two entries per row\n",
        "\t\t\ttemp_data_dict[column_labels[cndx]]=list(zip([data_strings[x] for x in range(cndx2,len(data_strings),entries_per_row)],[data_strings[x] for x in range(cndx2+1,len(data_strings),entries_per_row)]))\n",
        "\t\t  # count by N but make a list of tuples where each tuple contains two strings\n",
        "\t\t\n",
        "\t\tempty_dict[column_labels[cndx]]=[]\n",
        "\t\tif num_data_rows!=len(temp_data_dict[column_labels[cndx]]): # if we split up the strings wrong then we have something to debug\n",
        "\t\t\tprint('data size error 4')\n",
        "\t\t\terrorhere # a lazy way to make the code stop\n",
        "\t  \n",
        "\t# the object \"current_data_frame\" is initialized as empty but stores all the \n",
        "\t# data iteratively until we have all the data for a polling place, even if it \n",
        "\t# breaks accross pages. Once we have all the data for a polling place we start\n",
        "\t# with a new current_data_frame\n",
        "\n",
        "\t# initialize the current_data_frame if need be\n",
        "\tif current_data_frame['columns'] is None:\n",
        "\t\tcurrent_data_frame['columns']=deepcopy(empty_dict)\n",
        "\n",
        "\t# now split the columns in temp_data_dict into sections corresponding to polling places\n",
        "\tcurrent_ndx=0;\n",
        "\t# we step through removing data from temp_data_dict as we copy it into current_data_frame\n",
        "\t# we also copy and remove from row_labels which lets us know when we are done\n",
        "\t  \n",
        "\twhile len(row_labels)>0:\n",
        "\t\t# get a logical indicating which row_labels correspond to the ID of a polling place\n",
        "\t\tnext_polling_place_list=list(map(lambda x: len(x)>0 and x.startswith('W ') , row_labels));\n",
        "\t\t\n",
        "\t\tif any(next_polling_place_list): # if there are any more polling places\n",
        "\t\t  # get the index of where the next polling places data starts \n",
        "\t\t  # (should be 5 unless a polling place breaks accross pages)\n",
        "\t\t\tnext_ndx=next_polling_place_list.index(True) \n",
        "\t\t\tnext_Name=row_labels.pop(next_ndx); # get the name of the next polling place\n",
        "\t\t\n",
        "\t\telif len(row_labels)>5 and \"TOTAL\" not in row_labels[-1].upper(): # if there are more row labels for a polling place then we expect then we have something to debug\n",
        "\t\t\tprint('error')\n",
        "\t\t\tprint(row_labels)\n",
        "\t\t\terrorhere # a lazy way to make the code stop\n",
        "\t\t\n",
        "\t\telse: # if there are no more polling places then just take all the remaining data\n",
        "\t\t\tnext_ndx=len(row_labels)\n",
        "\t\t\tnext_Name=None;\n",
        "\n",
        "\t\t# according to the panda framework the row labels are called \"index\"\n",
        "\t\tcurrent_data_frame['index']=current_data_frame['index']+[row_labels.pop(current_ndx) for x in range(current_ndx,next_ndx)]\n",
        "\t\t\n",
        "    # now we step through the columns in temp_data_dict and extract the data from that\n",
        "\t\tfor k in current_data_frame['columns'].keys():\n",
        "\t\t\tcurrent_data_frame['columns'][k]=current_data_frame['columns'][k]+[temp_data_dict[k].pop(current_ndx) for x in range(current_ndx,next_ndx)] # temp_data_dict[k].pop(pop_list))\n",
        "\t\t\n",
        "\t\tcurrent_data_frame['collection_label']=collection_label\n",
        "\t\tif next_Name is not None: # this usually corresponds to city wide results\n",
        "\t\t\tdata_frames_to_save.append(current_data_frame)\n",
        "\t\t\tcurrent_data_frame={'Name':next_Name,'columns':deepcopy(empty_dict),'index':[]}\n",
        "  \n",
        "print(\"Section complete! Move on to the next section.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uc-h4M91gcOp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This scraper is not smart. It sometimes associates the wrong office to the candidate. Using the code below, you will be able to make sure that we have the correct office/candidate combination.<br>\n",
        "Since there is no page number associated, it will be useful to use Ctrl+F to find the candidates name in the pdf. "
      ]
    },
    {
      "metadata": {
        "id": "Tlew1twq590v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "candidateList = []\n",
        "officeCandidate = {}\n",
        "\n",
        "for item in data_frames_to_save:\n",
        "  \n",
        "  if not item['collection_label'] == 'TURN OUT':\n",
        "    \n",
        "    for k in item['columns'].keys():\n",
        "      \n",
        "        if k.startswith(\"Reg. Voters\") or k.startswith(\"Cards Cast\") or k.startswith(\"% Turnout\") or k.startswith(\"Times Counted\") or k.startswith(\"YES\") or k.startswith(\"NO\") or k.startswith(\"Total Votes\") or k.startswith(\"Write-In Votes\"): \n",
        "          continue\n",
        "        \n",
        "        else:\n",
        "          \n",
        "          if k not in candidateList:\n",
        "            candidateList.append(k)\n",
        "            print(\"Is {} associated with the office {}? Y or N\".format(k,item['collection_label']))\n",
        "            answer = input()\n",
        "            \n",
        "            if answer.upper() == \"Y\":\n",
        "              officeCandidate[k] = item['collection_label']\n",
        "            \n",
        "            else:\n",
        "              print(\"Enter the office as seen on the record: \")\n",
        "              response = input()\n",
        "              officeCandidate[k] = response.upper()\n",
        "            \n",
        "print(\"Success. All candidates have been checked! If the list below is not correct, rerun this cell: \")\n",
        "\n",
        "for k,v in officeCandidate.items():\n",
        "  print(\"{} - {}\".format(k,v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qv9iLh7rghQV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hooray, we have everything in order! Below we will write two files. The first file breaks down the detailed race information, including candidates. The second file will give us overall voter turnout per precinct. <br>\n",
        "They are written into Comma-Separated Value (csv) files, which can be opened in Tableau, Excel or any basic text editor. "
      ]
    },
    {
      "metadata": {
        "id": "w2lalPGZqW8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write out the two files we want\n",
        "\n",
        "#This file will hold the results for each race/candidate\n",
        "output = open(file+\"_results.csv\",\"w\")\n",
        "output.write(\"ward,precinct,race,type,candidate,votes\\n\")\n",
        "\n",
        "#This file will have overall turnout information\n",
        "out2 = open(file+\"_overall.csv\",'w')\n",
        "out2.write(\"ward,precinct,registered,polling,absentee,provisional,house,total\\n\")\n",
        "\n",
        "for item in data_frames_to_save:\n",
        "  if item['collection_label'] == 'TURN OUT':\n",
        "    if not item['Name'] == None:\n",
        "      ward = item['Name'][2:4]\n",
        "      precinct = item['Name'][-2:]\n",
        "      out2.write(\"{},{},{},{},{},{},{},{}\\n\".format(ward,precinct,item['columns']['Reg. Voters'][0],item['columns']['Cards Cast'][0],item['columns']['Cards Cast'][1],item['columns']['Cards Cast'][2],item['columns']['Cards Cast'][3],item['columns']['Cards Cast'][4]))\n",
        "  else:\n",
        "    for itemIndex in range(5):\n",
        "      for k in item['columns'].keys():\n",
        "        if k.startswith(\"Reg. Voters\") or k.startswith(\"Cards Cast\") or k.startswith(\"% Turnout\") or k.startswith(\"Total Votes\")or k.startswith(\"Times Counted\") or k.startswith(\"Write-In Votes\") or k.startswith(\"YES\") or k.startswith(\"NO\"): \n",
        "          continue\n",
        "        else:\n",
        "          num_votes = item['columns'][k][itemIndex][0]\n",
        "          if not num_votes=='-':\n",
        "            ward = item['Name'][2:4]\n",
        "            precinct = item['Name'][-2:]\n",
        "            output.write(\"{},{},{},{},{},{}\\n\".format(ward,precinct,officeCandidate[k],item['index'][itemIndex],k,num_votes))\n",
        "\n",
        "print(\"Success!\")\n",
        "output.close()\n",
        "out2.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t9LV0jBpS_Hg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The files should appear to the left under the tab Files. You may have to hit refresh _ON THE SIDEBAR_ (not your browser) in order to see them. \n",
        "You can quickly see if they look generally correct by double clicking the file. \n",
        "To download the file, right-click and choose Download.<br> <br>\n",
        "\n",
        "### Before closing this code, please download these files. They will disappear when this instance is closed<br> <br>\n",
        "\n",
        "After downloading, upload the copies to this [Google Drive folder](https://drive.google.com/drive/folders/1JNjUwriOtSPQsrDC-mqPbXb10tvi41hM?usp=sharing). Here you should also be able to access documents created by other groups. <br><br>\n",
        "\n",
        "After that, it's on to visualization and analysis!\n"
      ]
    }
  ]
}